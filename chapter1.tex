% From mitthesis package
% Version: 1.07, 2024/09/26
% Documentation: https://ctan.org/pkg/mitthesis


\chapter{Introduction}

The field of computational chemistry aims to use computers to simulate and better understand the behavior of complex chemical systems in the real world. Drug discovery, materials science, and nanotechnology are only a few areas that would benefit from the ability to computationally predict behavior of molecular systems. However, chemical systems at the particle level are inherently shaped by quantum effects, which are not easily modeled by a classical (non-quantum) computer. In particular, the phenomenon of quantum superposition allows a system to be in a linear combination of an exponential number of basis states at the same time. A classical computer must numerically store this exponential amount of data, a prohibitive task.

Quantum computational chemistry aims to perform this task using quantum computers, which can represent such systems more easily because its hardware, by definition, is inherently quantum. A superposition in a chemical system, for example, can represented by physically putting a quantum computer's hardware into superposition.

\section{Hamiltonian Simulation}

In any quantum system, the behavior in which its state changes over time is dictated by its Hamiltonian operator $\hat{H}$. In particular, if the system starts in state $\ket{\psi(0)}$, then we can determine its state $\ket{\psi(t)}$ at time $t$.

\begin{equation}
    \ket{\psi(t)} = e^{-i\hat{H}t}\ket{\psi(0)}
\end{equation}

Operators and states can be thought of as matrices and vectors, but where a vector maps integer indices to values, a state is a function that maps a continuous variable (such as position) to an amplitude value. An operator maps state functions to state functions how a matrix maps vectors to vectors.

The Hamiltonian $\hat{H}$ depends on many factors, such as the nature of interactions between particles in the system or external forces such as electric or magnetic fields acting in the system. $\hat{H}$, and in turn $U = e^{-i\hat{H}t}$ can be very complex, and usually it's not feasible to simulate $U$ exactly. Instead, we try find a different operator $\tilde{U}$ that is easy to simulate and sufficiently close to $\tilde{U}$. Usually we choose to define the error as the spectral norm (largest singular value) of the difference between $U$ and $\tilde{U}$. The goal is for the error to be below some variable threshold $\epsilon$.

\begin{equation}
    \epsilon \geq ||U - \tilde{U}|| = ||e^{-iHt} - \tilde{U}||
\end{equation}

This task is accordingly named Hamiltonian simulation.

One important Hamiltonian is the electronic structure Hamiltonian, describing the behavior of electrons in a molecule consisting of many nuclei and electrons. In modeling this system, we use the Born-Oppenheimer approximation, which assumes that the positions of the nuclei are essentially fixed. This is justified by the fact that the nuclei are far more massive than the electrons, so we can study the movement of electrons separately from the movement of the nuclei. With this assumption, the electronic structure Hamiltonian contains only terms for the electrons' kinetic energies, for the interactions between electrons and nuclei, and for the interactions among electrons.

\begin{equation}
    \hat{H} = -\sum_p \frac{\hbar^2}{2m_e} \nabla^2_p - \sum_{p, P}\frac{e^2}{4\pi\epsilon_0}\frac{Z_P}{|\vec{r}_p - \vec{R}_P|} + \frac{1}{2}\sum_{p \neq q}\frac{e^2}{4\pi\epsilon_0}\frac{1}{|\vec{r}_p - \vec{r}_q|} \label{eq: H}
\end{equation}

$\vec{r}_p$ denotes the position of the $p$th electron, and $\vec{r}_P$ and $Z_P$ denote the position and charge of the $P$th nucleus.

The ultimate goal of electronic structure theory is to find the eigenvalues and eigenstates of $e^{-i\hat{H}t}$, or the states that are invariant (up to a phase) under $e^{-i\hat{H}t}$. The ability to simulate the behavior of $e^{-i\hat{H}t}$ on an arbitrary state can directly be used to find the eigenvalues using the quantum phase estimation algorithm. The details of this algorithm are not essential in the topic of this paper, the relevant fact is the power unlocked by performing $e^{-i\hat{H}t}$.

\section{Trotterization}

The Hamiltonian $H$ of a system may often be a sum of many terms $\hat{h}_j$, as exemplified by the electronic structure Hamiltonian in $\eqref{eq: H}$.

\begin{equation}
    \hat{H} = \sum_j \hat{h}_j
\end{equation}

We can use the Lie-Trotter formula to approximate the target operator $U = e^{-i\hat{H}t}$ as the product of many smaller rotations.

\begin{equation}
    U = e^{-i\hat{H}t} = e^{-i\sum_j \hat{h}_jt} = \lim_{M \rightarrow \infty} (\prod_j e^{-i\hat{h}_j\frac{t}{M}})^M
\end{equation}

In other words, for sufficiently large $M$, $U$ is essentially equivalent to iterating $M$ times through smaller evolutions $e^{-i\hat{h}_j\frac{t}{M}}$. We can denote $\Delta t = \frac{t}{M}$ the step size. This is the first-order Trotter-Suzuki Algorithm. This is very convenient because it means that if we can simulate a Hamiltonian evolution with $\hat{h}_j$, we can also approximately simulate $U$. This will be the case most of the time in this paper.

However, $M$ must be sufficiently large to make the approximation sufficiently precise. At the same time, the computation cost of the algorithm scales linearly with the number of individual evolutions and therefore with $M$. It turns out that, to achieve an error threshold of $\epsilon$, a cost of $\frac{L^3\Lambda^2t^2}{\epsilon}$ is necessary, in which $L$ is the number of terms $h_j$, and $\Lambda = \max_j ||h_j||$.

First-order Trotterization as described is the most basic of such Hamiltonian simulation algorithms, and there is a rich field of literature finding improved methods to decrease error and computation cost for this problem.

One example is qDRIFT, a randomized version of first-order Trotterization. Its computation cost is $O(\frac{\lambda^2 t^2}{\epsilon})$, in which $\lambda = \sum_j ||h_j||$.

The power of such Trotter-like techniques (breaking $e^{-i\hat{H}t}$ into many $e^{-i\hat{h}_jt}$) allows us to analyze each term $\hat{h}_j$ independently of the others. If one can simulate $e^{-i\hat{h}_jt}$ for every term, one can simulate $U$.

\section{Second Quantized Fock States}

We would like to model the electronic structure system described by $\hat{H}$ in \eqref{eq: H}. As previously described, the system consists of numerous identical electrons and numerous nuclei at fixed positions. The indistinguishability of the electrons means that the joint wavefunction is only determined by how many electrons are in each basis state, rather than which electron is in which state. For example, electrons $1$ and $2$ being in respective states $\phi_1$ and $\phi_2$ must create the same wavefunction as them being in the states $\phi_2$ and $\phi_1$. In addition, the joint wavefunction of many identical fermions must be anti-symmetric upon exchange of any pair of fermions. For example, if we want to express a state where one electron is in state $\phi_1$ and the other is in state $\phi_2$, a simple tensor product $\phi_1 \otimes \phi_2$ would not be a valid joint wavefunction. Instead, it must be anti-symmetrized.

\begin{equation}
    \psi = \phi_1 \otimes \phi_2 - \phi_2 \otimes \phi_1
\end{equation}

This required process can make many-body calculations very cumbersome. Fortunately, second quantization significantly simplifies the representation of many-body systems by introducing the Fock basis, whose states are inherently anti-symmetrized.

Suppose for a single electron we'd like to use a basis $\{\phi_i\}$. Although the basis has infinite size, usually only basis states below a certain energy threshold are relevant, restricting our concern to a finite basis $\{\phi_i\}_{i \in [0, n)}$.

If there are many identical particles, we often want to express a state where $f_i$ particles are in the $\phi_i$ state. We can label such a state with a vector $\vec{f}$. This is a Fock state $\ket{\vec{f}}$. For fermions (such as electrons), $f_i \in \{0, 1\}$ due to the Pauli-Exclusion Principle, so $\vec{f} \in \{0, 1\}^n$.

\begin{equation}
    \ket{\vec{f}} = \ket{f_0, f_1, ..., f_{n - 1}} \label{eq: fock}
\end{equation}

With $n$ orbitals (basis states), there are $2^n$ such Fock states, one for each n-bitstring $\vec{f} \in \{0, 1\}^n$. These $2^n$ states form a complete basis of the many-body Hilbert space. That is, any state possible for a many-body system within these $n$ orbitals can be expressed as a linear combination of these Fock states.

We can define fermionic creation $a^\dag_i$ and annihilation $a_i$ operators that map Fock states to Fock states.

\begin{equation}
    \begin{split}
        a^\dag_i\ket{\vec{f}} &= a^\dag_i\ket{f_0, ..., f_{n - 1}} \\
        &= \delta_{f_i, 1}(-1)^{\sum_{j = 0}^{i - 1}}\ket{f_0, ..., f_i \oplus 1, ..., f_{n - 1}}
    \end{split}
    \label{eq: creation}
\end{equation}
\begin{equation}
    \begin{split}
        a_i\ket{\vec{f}} &= a_i\ket{f_0, ..., f_{n - 1}} \\
        &= \delta_{f_i, 0}(-1)^{\sum_{j = 0}^{i - 1}}\ket{f_0, ..., f_i \oplus 1, ..., f_{n - 1}}
    \end{split}
    \label{eq: annihilation}
\end{equation}

$a^\dag_i$ transforms a Fock state with $f_i = 0$ into a Fock state with $f_i = 1$, thereby ``creating'' a fermion in state $\phi_i$ and adding a phase shift to account for anti-symmetry. If orbital $i$ is already occupied, the new state is $0$ (it disappears). $a_i$ does the reverse of $a^\dag_i$ and de-occupies orbital $i$.

As typical with creation and annihilation operators, their product is a number operator $n_i = a^\dag_ia_i$ \cite{QCC}.

\begin{equation}
    n_i\ket{\vec{f}} = f_i\ket{f_0, ..., f_{n - 1}}
\end{equation}

The creation and annihilation operators have anti-commutation relations \cite{QCC} that are analogous to typical commutation relations of creation and annihilation operators.

\begin{equation}
    \{a^\dag_i, a_j\} = \delta_{i, j}
\end{equation}
\begin{equation}
    \{a_i, a_j\} = \{a^\dag_i, a^\dag_j\} = 0
\end{equation}

Second quantization, in short, equips us with a concise representation of many-fermion wavefunction in the form of Fock states and operators $a^\dag_i, a_i$ to easily manipulate them.

\section{Jordan-Wigner Transformation}

The Fock basis allows us to easily represent physical systems of many electrons. We would like to encode these physical systems on a quantum computer made of qubits so that we can compute on them. Conveniently, it is very straightforward to do so with the Fock basis.

Quantum computers are comprised of qubits. A qubit is simply a system with a two-dimensional Hilbert space. One example is an electron spin (up or down). Given a basis $\{\ket{0}, \ket{1}\}$, the state of a qubit can be any normalized linear combination of these two basis vectors.

\begin{equation}
    \ket{\psi} = A_0\ket{0} + A_1\ket{1} \text{ such that } |A_0|^2 + |A_1|^2 = 1
\end{equation}

The joint state of $n$ qubits can be any normalized superposition of all $2^n$ basis states $\{\ket{\vec{x}}\}_{\vec{x} \in \{0, 1\}^n} = \{\ket{x_0, x_1, ..., x_{n - 1}}\}_{\vec{x} \in \{0, 1\}^n}$.

\begin{equation}
    \ket{\psi} = \sum_{\vec{x} \in \{0, 1\}^n} A_{\vec{x}} \ket{\vec{x}} \text{ such that } \sum_{\vec{x} \in \{0, 1\}^n} |A_{\vec{x}}|^2 = 1 \label{eq: qubits}
\end{equation}

It is then straightforward that basis states \eqref{eq: fock} of an $n$-orbital many-electron physical system correspond to basis states \eqref{eq: qubits} of $n$ qubits in a quantum computer. This is the Jordan-Wigner Encoding.

\begin{equation}
    \ket{\vec{f}} \leftrightarrow \ket{\vec{x}}
\end{equation}

That is, in the Jordan-Wigner Encoding, the value $x_i$ of the $i$th qubit represents the occupation $f_i$ of the orbital $\phi_i$.

Accordingly, creation \eqref{eq: creation} and annihilation \eqref{eq: annihilation} operators on the physical system also correspond to qubit operators.

\begin{equation}
    a_i \leftrightarrow Z_0Z_1...Z_{i - 1}\ket{0}\bra{1}_i \label{eq: JWdown}
\end{equation}
\begin{equation}
    a^\dag_i \leftrightarrow Z_0Z_1...Z_{i - 1}\ket{1}\bra{0}_i \label{eq: JWup}
\end{equation}
\begin{equation}
    n_i = a^\dag_ia_i \leftrightarrow \ket{1}\bra{1}_i \label{eq: JWnum}
\end{equation}

We use the short-hand $U_i = I^{\otimes i}\otimes U \otimes I^{\otimes n - i - 1}$ to denote applying a gate $U$ on the $i$th qubit.

Observe that individual physical and annihilation operators map to a series of $i$ gates (qubit operators). In the average case, this amounts to $O(n)$ gates, which is not ideal. There are other encodings that optimize the efficiency of operator mappings, but they sacrifice the simplicity in basis state mappings exhibited by the Jordan-Wigner Encoding. For the purposes of this project, the Jordan-Wigner Encoding is sufficient.

\section{Double Factorization of Electronic Structure Hamiltonian}

Equipped with Fock states and creation and annihilation operators, we can rewrite the electron structure Hamiltonian from \eqref{eq: H} in a simpler, second-quantized form.

\begin{equation}
    \hat{H} = \sum_{i, j} h_{ij}a^\dag_ia_j + \frac{1}{2}\sum_{i,j,k,l} h_{ijkl}a^\dag_ia^\dag_ja_ka_l \label{eq: H2}
\end{equation}

The real coefficients $h_{ij}$ and $h_{ijkl}$ are the projections of $\hat{H}$ onto the chosen single-particle basis $\{\phi_i\}_{i \in [0, n)}$. These can be calculated on a classical computer.

\begin{equation}
    \begin{split}
        h_{ij} &= \braket{\phi_i | \left(-\frac{\hbar^2}{2m_e}\nabla^2 - \sum_I \frac{e^2}{4\pi\epsilon_0}\frac{Z_I}{|\vec{r} - \vec{R}_I|}\right) | \phi_j} \\
        &= \int \phi^*_i(\vec{r})\left(-\frac{\hbar^2}{2m_e}\nabla^2 - \sum_I \frac{e^2}{4\pi\epsilon_0}\frac{Z_I}{|\vec{r} - \vec{R}_I|}\right)\phi_j(\vec{r}) d^3\vec{r}
    \end{split}
    \label{eq: hij}
\end{equation}
\begin{equation}
    \begin{split}
        h_{ijkl} &= \braket{\phi_i, \phi_j | \frac{e^2}{4\pi\epsilon_0}\frac{1}{|\vec{r}_1 - \vec{r}_2|} | \phi_l, \phi_k} \\
        &= \iint \phi^*_i(\vec{r}_1)\phi^*_j(\vec{r}_2)\frac{e^2}{4\pi\epsilon_0}\frac{1}{|\vec{r}_1 - \vec{r}_2|}\phi_l(\vec{r}_1)\phi_k(\vec{r}_2) d^3\vec{r}_1d^3\vec{r}_2
    \end{split}
    \label{eq: hijkl}
\end{equation}

Observe from \eqref{eq: hij} that $h_{ij}$, which is real, must be symmetric between $i$ and $j$. From \eqref{eq: hijkl}, $h_{ijkl}$, which is also real, must also be symmetric between $i$ and $l$, $j$ and $k$, and $(i, l)$ and $(j, k)$. Inspired by this symmetry, we can rearrange the operators in the second summation using anti-commutation relations to put $i, l$ and $j, k$ next to each other.

\begin{equation}
    \begin{split}
        \hat{H} &= \sum_{i, j} h_{ij}a^\dag_ia_j + \frac{1}{2}\sum_{i,j,k,l} h_{ijkl}a^\dag_ia^\dag_ja_ka_l \\
        &= \sum_{i, j} h_{ij}a^\dag_ia_j - \frac{1}{2}\sum_{i,j,k,l} h_{ijkl}a^\dag_ia^\dag_ja_la_k \\
        &= \sum_{i, j} h_{ij}a^\dag_ia_j - \frac{1}{2}\sum_{i,j,k,l} h_{ijkl}a^\dag_i(\delta_{jl} - a_la^\dag_j)a_k \\
        &= \sum_{i, j} h_{ij}a^\dag_ia_j - \frac{1}{2}\left(\sum_{i, j, k}h_{ijkj}a^\dag_ia_k - \sum_{i,j,k,l} h_{ijkl}a^\dag_ia_la^\dag_ja_k\right) \\
        &= \sum_{i, j} (h_{ij} - \frac{1}{2}\sum_k h_{ikjk})a^\dag_ia_j + \frac{1}{2}\sum_{i,j,k,l} h_{ijkl}a^\dag_ia_la^\dag_ja_k \\
        &= \sum_{i, j} h'_{ij}a^\dag_ia_j + \frac{1}{2}\sum_{i,j,k,l} h'_{iljk}a^\dag_ia_la^\dag_ja_k \\
        &= \hat{H}_{1e} + \hat{H}_{2e}
    \end{split}
    \label{eq: H3}
\end{equation}
We introduced new coefficients $h'_{ij}$ and $h'_{iljk}$ for this new ordering and label the summations $\hat{H}_{1e}$ and $\hat{H}_{2e}$.
\begin{equation}
    \begin{split}
        h'_{ij} &= h_{ij} - \frac{1}{2}\sum_k h_{ikjk} \\
        \hat{H}_{1e} &= \sum_{i, j} h'_{ij}a^\dag_ia_j \\
        h'_{iljk} &= h_{ijkl} \\
        \hat{H}_{2e} &= \frac{1}{2}\sum_{i,j,k,l} h'_{iljk}a^\dag_ia_la^\dag_ja_k
    \end{split}
\end{equation}

As a reminder, we would like to simulate $U = e^{-i\hat{H}t}$ on a quantum computer. Trotterization allows us to study each term in \eqref{eq: H3} independently. That is, we just need to find a way to simulate $U_1 = e^{-i\hat{H}_{1e}\Delta t}$ and $U_2 = e^{-i\hat{H}_{2e}\Delta t}$ for arbitrary $\Delta t$. The direct brute force method is to substitute the operator correspondances from \eqref{eq: JWdown} and \eqref{eq: JWup} into \eqref{eq: H3} to obtain the corresponding qubit Hamiltonian. With this method, it turns out that $U_1$ is a sum of $O(n^2)$ terms and $U_2 = e^{-\hat{H}_{2e}t}$ becomes $O(n^4)$ terms. We can iterate over the terms with a Trotter-like or qDRIFT, but the $O(n^4)$ can make such an iteration very tedious. We'd like to see if there's a more clever method.

Recall that because $h'_{iljk} = h_{ijkl}$ is symmetric between $(i, l)$ and $(j, k)$, $h'$ can be treated as a real symmetric $n^2 \times n^2$ matrix and eigendecomposed with eigenvalues $\lambda_r$ and eigenvectors $Q^{(r)}$ whose indices are $(i, l)$ ordered pairs. A Cholesky decomposition is also an option but for now we will use an eigendecomposition.

\begin{equation}
    h'_{iljk} = \sum_r \lambda_r Q^{(r)}_{i, l}Q^{(r)}_{j, k}
\end{equation}

\begin{equation}
    \begin{split}
        \hat{H}_{2e} &= \frac{1}{2}\sum_{i,j,k,l} h'_{ijkl}a^\dag_ia_la^\dag_ja_k \\
        &= \frac{1}{2}\sum_{i,j,k,l} \sum_r \lambda_r Q^{(r)}_{i, l}Q^{(r)}_{j, k}a^\dag_ia_la^\dag_ja_k \\
        &= \frac{1}{2}\sum_r \lambda_r \sum_{i,l} Q^{(r)}_{i, l}a^\dag_ia_l\sum_{j,k}Q^{(r)}_{j, k}a^\dag_ja_k \\
        &= \frac{1}{2}\sum_r\lambda_r\left(\sum_{i,j} Q^{(r)}_{i, j}a^\dag_ia_j\right)^2 \\
        &= \sum_r \hat{H}_{2e}^{(r)}
    \end{split}
    \label{eq: DF}
\end{equation}

We have written $\hat{H}_{2e}$ as a sum of terms $\hat{H}_{2e}^{(r)}$. If we could simulate $U_2^{(r)} = e^{-i\hat{H}_{2e}^{(r)}\Delta t}$ for an arbitrary $\Delta t$, then we can Trotter or qDRIFT over these terms to implement $U_2$.

\begin{equation}
    \hat{H}_{2e}^{(r)} = \frac{1}{2}\lambda_r\left(\sum_{i,j} Q^{(r)}_{i, j}a^\dag_ia_j\right)^2
\end{equation}

Observe that $h'_{iljk}$ is symmetric between $i$ and $l$ and between $j$ and $k$, implying that $Q^{(r)}_{i, j}$ is symmetric between $i$ and $j$. Each $n^2$-length vector $Q^{(r)}$ can then be treated as an $n \times n$ matrix to be further eigendecomposed with eigenvalues $\lambda'^{(r)}_s$ and real orthonormal eigenvectors $R^{(r)}_s$ as the columns of $R^{(r)}$, which is orthogonal.

\begin{equation}
    \begin{split}
        Q^{(r)} &= R^{(r)}\begin{bmatrix}
            \lambda'^{(r)}_0 & & \\ & \ddots & \\ & & \lambda'^{(r)}_{n - 1}
          \end{bmatrix}R^{(r)T} \\
        Q^{(r)}_{i, j} &= \sum_s \lambda'^{(r)}_s R^{(r)}_{is}R^{(r)}_{js}
    \end{split}
\end{equation}

We introduce the operators $\tilde{a}^{(r)\dag}_s, \tilde{a}^{(r)}_s$, which are respectively linear combinations of the the creation operators $\{a^\dag_i\}_{i \in [0, n)}$ and annihilation operators $\{a_i\}_{i \in [0, n)}$. Because $R^{(r)}$ is orthogonal (and therefore unitary), these $\tilde{a}^{(r)\dag}_s, \tilde{a}^{(r)}_s$ are actually creation and annihilation operators of a different Fock basis; that is, the basis $\{\tilde{\phi}_s = \sum_s R^{(r)}_{is} \phi_i\}_{s \in [0, n)}$. This rotated basis also has its own number operators $\tilde{n}^{(r)}_s$.

\begin{equation}
    \begin{split}
        \tilde{a}^{(r)\dag}_s &= \sum_iR^{(r)}_{is}a^\dag_i \\
        \tilde{a}^{(r)}_s &= \sum_iR^{(r)}_{is}a_i \\
        \tilde{n}^{(r)}_s &= \tilde{a}^{(r)\dag}_s\tilde{a}^{(r)}_s
    \end{split}
\end{equation}

We can rewrite $\hat{H}_{2e}^{(r)}$ in terms of $\tilde{a}^{(r)\dag}_s, \tilde{a}^{(r)}_s, \tilde{n}^{(r)}_s$.

\begin{equation}
    \begin{split}
        H_{2e}^{(r)} &= \frac{1}{2}\lambda_r\left(\sum_{i,j} Q^{(r)}_{i, j}a^\dag_ia_j\right)^2 \\
        &= \frac{1}{2}\lambda_r\left(\sum_{i,j} \sum_s \lambda'^{(r)}_s R^{(r)}_{is}R^{(r)}_{js}a^\dag_ia_j\right)^2 \\
        &= \frac{1}{2}\lambda_r\left(\sum_s \lambda'^{(r)}_s \sum_i R^{(r)}_{is}a^\dag_i\sum_jR^{(r)}_{js}a_j\right)^2 \\
        &= \frac{1}{2}\lambda_r\left(\sum_s \lambda'^{(r)}_s \tilde{a}^{(r)\dag}_s\tilde{a}^{(r)}_s\right)^2 \\
        &= \frac{1}{2}\lambda_r\left(\sum_s \lambda'^{(r)}_s \tilde{n}^{(r)}_s\right)^2
    \end{split}
\end{equation}

We would like to simulate $U_2^{(r)} = e^{-i\hat{H}_{2e}^{(r)}\Delta T}$ for an arbitrary $\Delta t$. If the operator's eigenbasis were the same as the qubits' computational basis, it would be very simple. However, its eigenbasis is the Fock basis constructed from the rotated basis $\{\tilde{\phi}_s\}$. Meanwhile, the qubit computational basis $\{\ket{\vec{x}}\}$ corresponds to the original physical Fock basis $\{\ket{\vec{f}}\}$ constructed from $\{\phi_i\}$. To deal with this, we have to essentially rotate the operator $U_r$ into the computational basis. \cite{FSN} uses the Thouless Theorem to show that such a rotation operator $U_R(R^{(r)})$ necessary can be calculated from $R^{(r)}$ and and corresponds to a maximum of ${n \choose 2} = O(n^2)$ gates on the quantum computer. 

\begin{equation}
    U_2^{(r)} = e^{-\frac{i\Delta t}{2}\lambda_r\left(\sum_s \lambda'^{(r)}_s \tilde{n}^{(r)}_s\right)^2} = U_R(R^{(r)})^\dag e^{-\frac{i\Delta t}{2}\lambda_r\left(\sum_s \lambda'^{(r)}_s n_s\right)^2}U_R(R^{(r)}) = U_R(R^{(r)})^\dag U_A^{(r)}U_R(R^{(r)})
    \label{eq: U_2^r}
\end{equation}
\begin{equation}
    U_A^{(r)} = e^{-\frac{i\Delta t}{2}\lambda_r\left(\sum_s \lambda'^{(r)}_s n_s\right)^2}
\end{equation}

\subsection{Double-Factorized Expansion Method}

We'd like to find a qubit analog to $U_A^{(r)}$. One way is to expand the square inside $U_A^{(r)}$ and factor it into ${n + 1 \choose 2}$ individual operators, since the terms all commute. Let's call this the ``double-factorized expansion method'', or ``expansion method'' for short.

\begin{equation}
    \begin{split}
        U_A^{(r)} &= e^{-\frac{i\Delta t}{2}\lambda_r\left(\sum_s \lambda'^{(r)}_s n_s\right)^2} \\
        &= e^{-\frac{i\Delta t}{2}\lambda_r\sum_{s, s'} \lambda'^{(r)}_s\lambda'^{(r)}_{s'} n_sn_{s'}} \\
        &= \prod_{s, s'} e^{-\frac{i\Delta t}{2}\lambda_r\lambda'^{(r)}_s\lambda'^{(r)}_{s'} n_sn_{s'}} \\
        &= \prod_s e^{-\frac{i\Delta t}{2}\lambda_s(\lambda'^{(r)}_s)^2 n_s}\prod_{s < s'} e^{-i\Delta t\lambda_r\lambda'^{(r)}_s\lambda'^{(r)}_{s'} n_sn_{s'}}
        \label{eq: expansion}
    \end{split}
\end{equation}

Each operator with a single $n_s$ corresponds (up to a phase) to a $R_z$ operator on the $s$th qubit in a quantum computer. Each operator with $n_sn_{s'}$ corresponds (up to a phase) to a controlled $R_z$ operator on the $s$th and $s'$th qubits in a quantum computer. 
\begin{equation}
    e^{-\frac{i\Delta t}{2}\lambda_r(\lambda'^{(r)}_s)^2 n_s} \leftrightarrow R_z(-\frac{\Delta t}{2}\lambda_r(\lambda'^{(r)}_s)^2)_s
\end{equation}
\begin{equation}
    R_z(\varphi) = \begin{bmatrix}
        e^{-i\frac{\varphi}{2}} & 0 \\ 0 & e^{i\frac{\varphi}{2}}
    \end{bmatrix} = e^{-i\frac{\varphi}{2}}\begin{bmatrix}
        1 & 0 \\ 0 & e^{i\varphi}
    \end{bmatrix} = e^{-i\frac{\varphi}{2}}(\ket{0}\bra{0} + e^{i\varphi}\ket{1}\bra{1})
\end{equation}
\begin{equation}
    e^{-\frac{i\Delta t}{2}\lambda_r\lambda'^{(r)}_s\lambda'^{(r)}_{s'} n_sn_{s'}} \leftrightarrow CR_z(-\frac{\Delta t}{2}\lambda_r\lambda'^{(r)}_s\lambda'^{(r)}_{s'})_{s, s'}
\end{equation}
\begin{equation}
    CR_z(\varphi) = \begin{bmatrix}
        1 & 0 & 0 & 0 \\ 0 & 1 & 0 & 0 \\ 0 & 0 & 1 & 0 \\ 0 & 0 & 0 & e^{i\varphi}
    \end{bmatrix}
    \label{eq: CR_z}
\end{equation}

There are therefore $n$ $R_z$ operators and ${n \choose 2}$ $CR_z$ operators in this decomposition. Each $CR_z$ can be decomposed to two $CNOT$s and three $R_z$s, shown in \ref{fig: CR_z}. This results in $n + 3{n \choose 2} = \frac{3n(n - 1)}{2}$ $R_z$ gates total in $U_A^{(r)}$.

\begin{figure}[h]
    \centering
    \Qcircuit @C=1em @R=1.6em {
        \lstick{} & \gate{R_z(\frac{\varphi}{4})} & \ctrl{1} & \qw & \ctrl{1} & \qw \\
        \lstick{} & \gate{R_z(\frac{\varphi}{4})} & \targ    & \gate{R_z(-\frac{\varphi}{4})} & \targ & \qw 
    }
    \caption{Construction of $CR_z(\varphi)$ in \eqref{eq: CR_z} with two $CNOT$ gates and three $R_z$ gates}
    \label{fig: CR_z}
\end{figure}

\cite{Rz} achieves a fault-tolerant implementation of $R_z$ using at most $10 + 4\log_2(\frac{1}{\epsilon_z})$ T-gates, in which $\epsilon_z$ is the the desired error bound of $R_z$. Since $U_A^{(r)}$ contains $\frac{3n(n - 1)}{2}$ $R_z$ gates and error (which is by operator norm) propagates sub-additively, we need $\epsilon_z \leq \frac{\epsilon}{\frac{3n(n - 1)}{2}}$ to guarantee a threshold $\epsilon$ for the error of $U_A^{(r)}$.

We can then calculate the upper bound for the T-count $\tilde{N}_T$ of $U_A^{(r)}$ using the expansion method in terms of $n, \frac{1}{\epsilon}$.

\begin{equation}
    \begin{split}
        \tilde{N}_T &= \frac{3n(n - 1)}{2}(10 + \log_2(\frac{1}{\epsilon_z})) \\
        &= \frac{3n(n - 1)}{2}(10 + \log_2(\frac{\frac{3n(n - 1)}{2}}{\epsilon})) \\
        &= O(n^2\log_2(\frac{n}{\epsilon}))
    \end{split}
    \label{eq: expansionTs}
\end{equation}

\subsection{Discussion}

Similarly to \eqref{eq: expansion}, $U_R(R^{(r)})$ in \eqref{eq: U_2^r} can be decomposed into at most $O(n^2)$ non-Clifford gates as described in \cite{FSN}, resulting in a $O(n^2\log_2(\frac{n}{\epsilon}))$ T-count. Combined with \eqref{eq: expansionTs}, one can achieve an overall T-count of $O(n^2\log_2(\frac{n}{\epsilon}))$ for $U_2^{(r)}$.

We'd like to find alternative fault-tolerant implementations of $U_2^{(r)}$ with a lower asymptotic $T$-count. For this to be possible, the chemical system must have a Hamiltonian with ``easy'' basis rotations; that is, it double factorizes such that all $U_R(R^{(r)})$ decomposes using the \cite{FSN} method to $o(n^2)$ non-Clifford gates. We also need to both implement $U_A^{(r)}$ more efficiently.

Chapter 2 introduces and explicitly constructs a quantum circuit that simulates $U_R(R^{(r)})$ with $O(n\log_2(\frac{n}{\epsilon}) + \log_2(\frac{1}{\epsilon})^2)$ $T$-count. We call this quantum circuit the ``coherent method'', in contrast to the ``expansion method''. Chapter 3 explores types of Hamiltonians with ``easy'' basis rotations and how to effectively leverage the ``coherent method'' for these Hamiltonians.

%%%%%%%%%%%%%%%% end table %%%%%%%%%%%%%%%%%%% 

